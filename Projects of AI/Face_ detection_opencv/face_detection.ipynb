{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[147, 149, 150],\n",
       "        [146, 148, 149],\n",
       "        [146, 148, 149],\n",
       "        ...,\n",
       "        [ 99,  78,  80],\n",
       "        [ 99,  78,  80],\n",
       "        [ 98,  77,  79]],\n",
       "\n",
       "       [[148, 150, 151],\n",
       "        [147, 149, 150],\n",
       "        [146, 148, 149],\n",
       "        ...,\n",
       "        [101,  80,  82],\n",
       "        [100,  79,  81],\n",
       "        [ 99,  78,  80]],\n",
       "\n",
       "       [[148, 150, 151],\n",
       "        [148, 150, 151],\n",
       "        [147, 149, 150],\n",
       "        ...,\n",
       "        [101,  80,  82],\n",
       "        [ 99,  78,  80],\n",
       "        [ 98,  77,  79]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[177, 202, 218],\n",
       "        [174, 199, 215],\n",
       "        [172, 197, 213],\n",
       "        ...,\n",
       "        [155, 177, 195],\n",
       "        [146, 168, 186],\n",
       "        [143, 165, 183]],\n",
       "\n",
       "       [[177, 203, 217],\n",
       "        [172, 198, 212],\n",
       "        [169, 195, 209],\n",
       "        ...,\n",
       "        [149, 171, 189],\n",
       "        [137, 159, 177],\n",
       "        [133, 155, 173]],\n",
       "\n",
       "       [[175, 201, 215],\n",
       "        [169, 195, 209],\n",
       "        [166, 192, 206],\n",
       "        ...,\n",
       "        [145, 167, 185],\n",
       "        [139, 161, 179],\n",
       "        [138, 160, 178]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('any img',1) \n",
    "img  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 1200, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=4, minSize=(60, 60))\n",
    "\n",
    "# Draw rectangles around the detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow('first image ',img)\n",
    "k= cv2.waitKey(0)\n",
    "\n",
    "if k == 27:\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "elif k == ord('s'):\n",
    "    cv2.imwrite('ssecand image.jpeg',img)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
